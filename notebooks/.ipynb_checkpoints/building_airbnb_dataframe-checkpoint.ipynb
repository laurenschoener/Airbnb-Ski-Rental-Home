{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All URLs I would like to include:\n",
    "breckinridge = 'https://www.airbnb.com/s/Breckenridge--CO/homes?adults=1&place_id=ChIJwecmbD32aocReqKAZn-PjWI&refinement_paths%5B%5D=%2Fhomes'\n",
    "parkcity = 'https://www.airbnb.com/s/Park-City--UT/homes?adults=1&place_id=ChIJ_QNjLGMPUocRlFc3Jd_Ecdg&refinement_paths%5B%5D=%2Fhomes'\n",
    "jacksonhole = 'https://www.airbnb.com/s/Jackson-Hole--WY/homes?adults=1&place_id=ChIJS3_P_FgaU1MRXIM6scsBHD0&refinement_paths%5B%5D=%2Fhomes'\n",
    "vail = 'https://www.airbnb.com/s/Vail--CO/homes?adults=1&place_id=ChIJB89dUQVwaocRxKOafh_AzMk&refinement_paths%5B%5D=%2Fhomes'\n",
    "steamboat = 'https://www.airbnb.com/s/Steamboat-Springs--CO/homes?adults=1&place_id=ChIJYUZWCYF7QocRfc9uSNGjqBs&refinement_paths%5B%5D=%2Fhomes'\n",
    "bigsky = 'https://www.airbnb.com/s/Big-Sky--MT/homes?adults=1&place_id=ChIJNSw3_WUOUFMRyiuLqjtx-JU&refinement_paths%5B%5D=%2Fhomes'\n",
    "telluride = 'https://www.airbnb.com/s/Telluride--CO/homes?adults=1&place_id=ChIJc_TmcHvYPocR4eO6cSF37jg&refinement_paths%5B%5D=%2Fhomes'\n",
    "aspen = 'https://www.airbnb.com/s/Aspen--CO/homes?adults=1&place_id=ChIJfTxB93w5QIcRcvYseNxCK8E&refinement_paths%5B%5D=%2Fhomes'\n",
    "tahoe = 'https://www.airbnb.com/s/Lake-Tahoe/homes?adults=1&place_id=ChIJUREfuaF4mYARILWv7q8fP4w&refinement_paths%5B%5D=%2Fhomes'\n",
    "taos = 'https://www.airbnb.com/s/Taos--NM/homes?adults=1&place_id=ChIJsfwRf9pkF4cRgrepYYOR6pA&refinement_paths%5B%5D=%2Fhomes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-68a158f3dae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mgetRoomInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlisting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mgetBasicFacilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlisting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mgetListingPrice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlisting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mgetListingRating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlisting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mgetListingReviewNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlisting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-95e004cb4b40>\u001b[0m in \u001b[0;36mgetListingPrice\u001b[0;34m(listing)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetListingPrice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlisting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlisting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"_1p7iugi\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    soupPage = getPage(url[1])\n",
    "    listing_lst = getRoomClasses(soupPage)\n",
    "    for listing in listing_lst:\n",
    "        getListingLink(listing)\n",
    "        getListingTitle(listing)\n",
    "        getTopRow(listing)\n",
    "        getRoomInfo(listing)\n",
    "        getBasicFacilities(listing)\n",
    "        getListingPrice(listing)\n",
    "        getListingRating(listing)\n",
    "        getListingReviewNumber(listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(url):\n",
    "    result = requests.get(url)\n",
    "    content = result.content\n",
    "    BeautifulSoup(content, features = \"lxml\")\n",
    "    return BeautifulSoup(content, features = \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information on different listings is shown with an image and information under the class '_8ssblpx'\n",
    "def getRoomClasses(soupPage):\n",
    "    rooms = soupPage.findAll(\"div\", {\"class\": \"_8ssblpx\"})\n",
    "    result = []\n",
    "    for room in rooms:\n",
    "        result.append(room)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListingLink(listing):\n",
    "    return \"http://airbnb.com\" + listing.find(\"a\")[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListingTitle(listing):\n",
    "    return listing.find(\"meta\")[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopRow(listing):\n",
    "    return listing.find(\"div\", {\"class\": \"_167qordg\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRoomInfo(listing):\n",
    "    return listing.find(\"div\", {\"class\": \"_kqh46o\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBasicFacilities(listing):\n",
    "    try:\n",
    "        output = listing.findAll(\"div\", {\"class\": \"_kqh46o\"})[1].text.replace(\" \",\"\")\n",
    "    except:\n",
    "        output = []\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListingPrice(listing):\n",
    "    return listing.find(\"div\", {\"class\": \"_1p7iugi\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListingRating(listing):\n",
    "    return listing.find(\"span\", {\"class\": \"_krjbj\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListingReviewNumber(listing):\n",
    "    try:\n",
    "        output = listing.findAll(\"span\", {\"class\": \"_krjbj\"})[1].text\n",
    "    except:\n",
    "        output = -1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInformation(soupPage):\n",
    "    listings = getRoomClasses(soupPage)\n",
    "    titles, links, toprows, roominfo, basicfacilities, prices, ratings, reviews = [], [], [], [], [], [], [], []\n",
    "    for listing in listings:\n",
    "        titles.append(getListingTitle(listing))\n",
    "        links.append(getListingLink(listing))\n",
    "        toprows.append(getListingLink(listing))\n",
    "        roominfo.append(getListingLink(listing))\n",
    "        basicfacilities.append(getListingLink(listing))\n",
    "        prices.append(getListingLink(listing))\n",
    "        ratings.append(getListingLink(listing))\n",
    "        reviews.append(getListingLink(listing))\n",
    "    dictionary = {\"title\": titles, \"toprow\": toprows, \"roominfo\": roominfo, \"facilities\": basicfacilities, \"price\": prices, \"rating\": ratings, \"link\": links, \"review\": reviews}\n",
    "    return pd.DataFrame(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNextPage(soupPage):\n",
    "    try:\n",
    "        nextpage = \"https://airbnb.com\" + soupPage.find(\"li\", {\"class\": \"_i66xk8d\"}).find(\"a\")[\"href\"]\n",
    "    except:\n",
    "        nextpage = \"no next page\"\n",
    "    return nextpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPages(url):\n",
    "    result = []\n",
    "    while url != \"no next page\":\n",
    "        page = getPage(url)\n",
    "        result = result + [page]\n",
    "        url = findNextPage(page)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPages(url):\n",
    "    pages = getPages(url)\n",
    "    df = extractInformation(pages[0])\n",
    "    for pagenumber in range(1, len(pages)):\n",
    "        df = df.append(extractInformation(pages[pagenumber]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [[\"Breckinridge\", breckinridge], \n",
    "           [\"Park City\", parkcity],\n",
    "           [\"Jacksonhole\", jacksonhole],\n",
    "           [\"Vail\", vail], \n",
    "           [\"Steamboat Springs\", steamboat],\n",
    "           [\"Big Sky\", bigsky],\n",
    "           [\"Telluride\", telluride],\n",
    "           [\"Aspen\", aspen],\n",
    "           [\"Lake Tahoe\", tahoe],\n",
    "           [\"Taos\", taos]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeURLs(listofURLs):\n",
    "    print(listofURLs[0][0])\n",
    "    df = extractPages(listofURLs[0][1])\n",
    "    df.loc[:, \"city\"] = listofURLs[0][0]\n",
    "    for i in range(1, len(listofURLs)):\n",
    "        print(listofURLs[i][0])\n",
    "        newrows = extractPages(listofURLs[i][1])\n",
    "        newrows.loc[:, \"city\"] = listofURLs[i][0]\n",
    "        df = df.append(newrows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDescription(detailpage):\n",
    "    return detailpage.find(\"div\",{\"class\": \"_eeq7h0\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetailedScores(detailpage):\n",
    "    output = []\n",
    "    scores = detailpage.findAll(class_ = '_a3qxec')\n",
    "    try:\n",
    "        for i in range(0, 6):\n",
    "            split = scores[i].text.split(\".\")\n",
    "            output.append(float(split[0][-1] + \".\" + split[1]))\n",
    "    except:\n",
    "        pass\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHostInfo(detailpage):\n",
    "    return detailpage.find(class_ = \"_f47qa6\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupDriver(url, waiting_time = 2.5):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(waiting_time)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJSpage(url):\n",
    "    driver = setupDriver(url)\n",
    "    read_more_buttons = driver.find_elements_by_class_name(\"_1d079j1e\")\n",
    "    try:\n",
    "        for i in range(2, len(read_more_buttons)):\n",
    "            read_more_buttons[i].click()\n",
    "    except:\n",
    "        pass\n",
    "    html = driver.page_source\n",
    "    driver.close()\n",
    "    return BeautifulSoup(html, features = \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAmenitiesPage(detailpage):\n",
    "    \n",
    "    link = detailpage.find(class_ = \"_1v4ygly5\")[\"href\"]\n",
    "    driver = setupDriver(\"https://airbnb.com\" + link, 5)\n",
    "    html = driver.page_source\n",
    "    driver.close()\n",
    "    return BeautifulSoup(html, features = \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "scraped = 0\n",
    "def getAddis(url):\n",
    "    global first\n",
    "    global scraped\n",
    "    output = pd.DataFrame(columns=[\"details_page\", \"amenities_page\", \"link\"])\n",
    "    try:\n",
    "        dp = getJSpage(url)\n",
    "        output.loc[0] = [dp, getAmenitiesPage(dp), url]\n",
    "    except:\n",
    "        output.loc[0] = [-1, -1, url]\n",
    "    if first:\n",
    "        output.to_csv('intermediate_results_par.csv', mode='a', header=True, index=False)\n",
    "        first = False\n",
    "    else:\n",
    "        output.to_csv('intermediate_results_par.csv', mode='a', header=False, index=False)\n",
    "    scraped += 1\n",
    "    print(\"Scraped: {}\".format(scraped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReviews(detailpage):\n",
    "    reviews = detailpage.findAll(class_ = \"_50mnu4\")\n",
    "    output = \"\"\n",
    "    for review in reviews:\n",
    "        output += review.text + \"**-**\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAmenities(amenitiespage):\n",
    "    amenities = amenitiespage.findAll(class_ = \"_vzrbjl\")\n",
    "    output = \"\"\n",
    "    for amenity in amenities:\n",
    "        output += re.findall('[A-Z][^A-Z]*', amenity.text)[0] + \"**-**\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponseInfo(detailpage):\n",
    "    try:\n",
    "        output = detailpage.find(class_ = \"_jofnfy\").text\n",
    "    except:\n",
    "        output = \"\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFacilities(df):\n",
    "    df.loc[:, \"facilities\"] = df[\"facilities\"].astype(str).str.replace(\"[\",\"\").str.replace(\"]\",\"\")\n",
    "    vectorizer = CountVectorizer(decode_error = \"ignore\")\n",
    "    X = vectorizer.fit_transform(df.facilities)\n",
    "    bag_of_words = pd.DataFrame(X.toarray(), columns=vectorizer.get_features_names())\n",
    "    return pd.concat([df.reset_index(drop=True).drop(\"facilities\", axis=1), bag_of_words], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTitle(df):\n",
    "    df.loc[:, \"name\"] = df[\"title\"].str.split(\" null \", n=0, expand=True)[0].str.replace(\"-\", \"\")\n",
    "    df.loc[:, \"location\"] = df[\"title\"].str.split(\" null \", n=0, expand=True)[1].str.replace(\"-\",\"\").str.strip()\n",
    "    return df.drop(\"title\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTopRow(df):\n",
    "    df.loc[:, 'roomtype'] = df[\"toprow\"].str.split(\" in \", n=0, expand=True)[0]\n",
    "    df.loc[:, 'detailed_location'] = df[\"toprow\"].str.split(\" in \", n=0, expand=True)[1]\n",
    "    return df.drop(\"toprow\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanRoomInfo(df):\n",
    "    df.loc[:, \"guests\"] = df.loc[:, \"roominfo\"].str.split(\" . \", n=0, expand=True)[0].str.replace(\"guests\", \"\")\n",
    "    df.loc[:, \"bedrooms\"] = df.loc[:, \"roominfo\"].str.split(\" . \", n=0, expand=True)[1]\n",
    "    df.loc[:, \"beds\"] = df.loc[:, \"roominfo\"].str.split(\" . \", n=0, expand=True)[2].str.replace(\" bed\",\"\").str.replace(\"s\", \"\")\n",
    "    df.loc[:, \"bathrooms\"] = df.loc[:, \"roominfo\"].str.split(\" . \", n=0, expand=True)[3]\n",
    "    df.loc[:, \"guests\"] = pd.to_numeric(df.guests, errors='coerce')\n",
    "    df.loc[:, \"beds\"] = pd.to_numeric(df.beds, errors='coerce')\n",
    "    df.loc[:, \"bedrooms\"] = pd.to_numeric(df.bedrooms.str.split(\" \", n=0, expand=True)[0], errors=\"ignore\")\n",
    "    df.loc[:, \"bathrooms\"] = pd.to_numeric(df.bathrooms.str.split(\" \", n=0, expand=True)[0], errors=\"ignore\")\n",
    "    return df.drop(\"roominfo\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanPrice(df):\n",
    "    df.loc[:, \"pricepernight\"] = df.loc[:, \"price\"].str.split(\"Discounted\", n=0, expand=True)[0].str.replace(\"$\", \"/\").str.split(\"/\", n=0, expand=True)[1]\n",
    "    df.loc[:, \"discountedpricepernight\"] = df.loc[:, \"price\"].str.split(\"Discounted\", n=0, expand=True)[1].str.replace(\"$\", \"/\").str.split(\"/\", n=0, expand=True)[1]\n",
    "    df.loc[:, \"price\"] = pd.to_numeric(df.pricepernight.str.replace(\",\",\"\").str.strip())\n",
    "    df.loc[:, \"discountedprice\"] = pd.to_numeric(df.discountedpricepernight.str.replace(\" \", \"\").str.replace(\",\",\"\"), errors=\"coerce\")\n",
    "    return df.drop([\"pricepernight\", \"discountedpricepernight\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanRating(df):\n",
    "    df.loc[:, \"score\"] = df.loc[:, \"rating\"].str.split(\" \", n=0, expand=True)[1]\n",
    "    df.loc[:, \"score\"] = pd.to_numeric(df.score, errors=\"coerce\")\n",
    "    return df.drop(\"rating\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanReviewNumber(df):\n",
    "    df.loc[:, \"reviewnumber\"] = df.loc[:, \"reviewnumber\"].str.split(\" \", n=0, expand=True)[0]\n",
    "    df.loc[:, \"reviewnumber\"] = pd.to_numeric(df.reviewnumber, errors=\"coerce\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = cleanTitle(df)\n",
    "    df = clenFacilities(df)\n",
    "    df = cleanTopRow(df)\n",
    "    df = cleanPrice(df)\n",
    "    df = cleanRating(df)\n",
    "    df = cleanReviewNumber(df)\n",
    "    col1 = df.pop(\"price\")\n",
    "    df = pd.concat([df.reset_index(drop=True), col1], axis=1)\n",
    "    col2 = df.pop(\"reviewnumber\")\n",
    "    df = pd.concat([df.reset_index(drop=True), col2], axis=1)\n",
    "    col3 = df.pop(\"link\")\n",
    "    df = pd.concat([df.reset_index(drop=True), col3], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAmenities(df):\n",
    "    df.loc[:, \"amenities\"] = df.amenities.replace(np.nan, \"\", regex=True)\n",
    "    df.loc[:, \"amenities\"] = df.amenities.str.replace(\" \", \"_\").str.replace(\"-\", \" \").str.replace(\"*\", \"\")\n",
    "    vectorizer = CountVectorizer(decode_error=\"ignore\")\n",
    "    X = vectorizer.fit_transform(df.amenities)\n",
    "    bag_of_words = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    return pd.concat([df.reset_index(drop=True).drop(\"amenities\", axis=1), bag_of_words], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanReviews(df):\n",
    "    df.loc[:, \"reviews\"] = df.reviews.replace(np.nan, \"\", regex=True)\n",
    "    df.loc[:, \"reviews\"] = df.reviews.str.split(\"-\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponseTime(string):\n",
    "    if \"Response time\" in string:\n",
    "        output = string[string.find(\"Response time\") + 15:]\n",
    "    else:\n",
    "        output = \"Unknown\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponseRate(string):\n",
    "    if \"Response rate\" in string:\n",
    "        temp = string[string.find(\"Response rate\") + 15:string.find(\"Response rate\")+20]\n",
    "        output = \"\"\n",
    "        for letter in temp:\n",
    "            if letter in \"0123456789\":\n",
    "                outpput += letter\n",
    "    else:\n",
    "        output = \"Unknown\"\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLanguages(string):\n",
    "    if \"Language\" in string:\n",
    "        if \"Response\" in string:\n",
    "            output = string[10:string.find(\"Response\")].strip()\n",
    "        else:\n",
    "            output = string[10:].strip()\n",
    "    else:\n",
    "        output = \"Unknown\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanResponseTime(df):\n",
    "    df.loc[:, \"response_info\"] = df.response_info.replace(np.nan, \"\", regex=True)\n",
    "    df.loc[:, \"response_time\"] = df.response_info.apply(lambda x: getResponseTime(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanResponseRate(df):\n",
    "    df.loc[:, \"response_rate\"] = df.response_info.apply(lambda x: getResponseRate(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanLanguages(df):\n",
    "    df.loc[:, \"languages\"] = df.response_info.apply(lambda x: getLanguages(x))\n",
    "    df.loc[:, \"languages\"] = df.languages.str.split(\",\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanResponseInfo(df):\n",
    "    df = cleanResponseTime(df)\n",
    "    df = cleanResponseRate(df)\n",
    "    df = cleanLanguages(df)\n",
    "    return df.drop(\"response_info\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(urls, sample_size=None, random_state=1234):\n",
    "    df = scrapeURLs(urls)\n",
    "    df = clean(df)\n",
    "    if sample_size is not None:\n",
    "        df = df.sample(sample_size, random_state = random_state)\n",
    "    Parallel(n_jobs=-1, prefer=\"threads\")(delayed(getAddis)(url) for url in df.link)\n",
    "    df2 = pd.read_csv(\"intermediate_results_par.csv\")\n",
    "    df = df.merge(df2, on=\"link\")\n",
    "    df.loc[:, \"reviews\"] = df.details_page.apply(lambda x: getReviews(BeautifulSoup(x, features=\"lxml\")))\n",
    "    df.loc[:, \"response_info\"] = df.details_page.apply(lambda x: getResponseInfo(BeautifulSoup(x, features=\"lxml\")))\n",
    "    df.loc[:, \"amenities\"] = df.amenities_page.apply(lambda x: getAmenities(BeautifulSoup(x, features=\"lxml\")))\n",
    "    df = cleanReviews(df)\n",
    "    df = cleanResponseInfo(df)\n",
    "    df = cleanAmenities(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
